{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jqxu/anaconda3/envs/mmretinal/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /home/jqxu/Ragas/RETCLIP/RET_CLIP/clip/model_configs/ViT-B-16.json\n",
      "Loading text model config from /home/jqxu/Ragas/RETCLIP/RET_CLIP/clip/model_configs/RoBERTa-wwm-ext-base-chinese.json\n",
      "Model info {'embed_dim': 512, 'image_resolution': 224, 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 12, 'text_type_vocab_size': 2}\n",
      "transformer int finished\n",
      "vit int finished\n",
      "loaded ret-clip vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 131.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 3.1952\n",
      "Image_path: /mnt/data/public/MM_Retinal_Image/MM_Retinal_dataset_v1/CFP/figure04-74B.jpg\n",
      "description: Fundus color image of systemic lupus erythematosus fundopathy in the left eye. Same patient as Figure 4-74A. The fundus presentation is similar to that of the right eye\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nos.environ[\\'http_proxy\\'] = \\'http://127.0.0.1:1087\\'\\nos.environ[\\'https_proxy\\'] = \\'http://127.0.0.1:1087\\'\\nprint(\"HTTP Proxy:\", os.environ.get(\\'http_proxy\\'))\\nprint(\"HTTPS Proxy:\", os.environ.get(\\'https_proxy\\'))\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "from KeepFIT.keepfit.modeling.model import KeepFITModel\n",
    "from retriever import TextRetriever, MMRetriever\n",
    "import torch\n",
    "import os\n",
    "'''\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:1087'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:1087'\n",
    "print(\"HTTP Proxy:\", os.environ.get('http_proxy'))\n",
    "print(\"HTTPS Proxy:\", os.environ.get('https_proxy'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /home/jqxu/Ragas/RETCLIP/RET_CLIP/clip/model_configs/ViT-B-16.json\n",
      "Loading text model config from /home/jqxu/Ragas/RETCLIP/RET_CLIP/clip/model_configs/RoBERTa-wwm-ext-base-chinese.json\n",
      "Model info {'embed_dim': 512, 'image_resolution': 224, 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 12, 'text_type_vocab_size': 2}\n",
      "transformer int finished\n",
      "vit int finished\n",
      "loaded ret-clip vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 388.21it/s]\n",
      "/home/jqxu/anaconda3/envs/mmretinal/lib/python3.9/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:00<00:00, 322.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights: None\n",
      "load model weight from: /home/jqxu/Ragas/KeepFIT/results/pretraining/50%flair+MM/KeepFIT (50%flair+MM).pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KeepFITModel(\n",
       "  (vision_model): VisionModel(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "    (projection_head_vision): ProjectionLayer(\n",
       "      (projection): Linear(in_features=2048, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (text_model): TextModel(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (projection_head_text): ProjectionLayer(\n",
       "      (projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (attention): MultiHeadAttention(\n",
       "    (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mmRetriever=MMRetriever(device=device,dataset_path=\"/home/jqxu/Ragas/MM_feature_set/RET-clip_modified\")\n",
    "textRetriever=TextRetriever(device=device,dataset_path=\"/home/jqxu/Ragas/text_datasets/dpr-txt/combined_books\")\n",
    "model = KeepFITModel(vision_type='resnet_v2', out_path='./output', from_checkpoint=True,\n",
    "                        vision_pretrained=True,\n",
    "                        weights_path=f'/home/jqxu/Ragas/KeepFIT/results/pretraining/50%flair+MM/KeepFIT (50%flair+MM).pth')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/CazeroZ/Images/raw/master/figure01-05-13a.jpg\n"
     ]
    }
   ],
   "source": [
    "from extract.extractor import Extractor\n",
    "from query_processor import QueryProcessor\n",
    "import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from get_api_key import read_api_key\n",
    "api_key =read_api_key(\"api_key.txt\")\n",
    "mmdataset = datasets.load_from_disk(\"/home/jqxu/Ragas/MM_feature_set/RET-clip_modified\")\n",
    "\n",
    "keyWordExtractor=Extractor(model='gpt-3.5-turbo',api_key=api_key)\n",
    "headers={\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "queryProcessor=QueryProcessor(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n",
    "results = []\n",
    "if os.path.exists(\"./results_tmp/result_Retclip.json\"):\n",
    "    with open(\"./results_tmp/result_Retclip.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "        try:\n",
    "            existing_data = json.load(json_file)\n",
    "            results = existing_data  # 将已有数据加载到 results 列表中\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"现有的JSON文件可能损坏或格式不正确，创建新的JSON文件。\")\n",
    "            results = []\n",
    "\n",
    "unchecked_samples = [sample for sample in mmdataset if not os.path.exists(os.path.join(\"/home/jqxu/Ragas/datasets\", os.path.basename(sample['image_path'])))]\n",
    "\n",
    "random_samples = random.sample(unchecked_samples, 40)\n",
    "\n",
    "def process_sample(sample):\n",
    "    img_path = sample['image_path']\n",
    "    img_name = os.path.basename(img_path)\n",
    "\n",
    "    scores, retrieved_examples = mmRetriever.retrieve(img_path, k=3)\n",
    "    similar_img_path = retrieved_examples[\"image_path\"][0]\n",
    "    similar_description = retrieved_examples[\"description\"][0]\n",
    "    \n",
    "    description = sample[\"description\"]\n",
    "    keywords = keyWordExtractor(similar_description)\n",
    "    \n",
    "    scores, retrieved_texts = textRetriever.retrieve(query=keywords, k=3, is_keywords=True)\n",
    "    combined_texts = [f\"{title}: {text}\" for title, text in zip(retrieved_texts[\"title\"], retrieved_texts[\"text\"])]\n",
    "    \n",
    "    # 定义一个用于存储查询结果的空字典\n",
    "    result = {}\n",
    "\n",
    "    # 重试机制：最多重试3次\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            # 处理查询结果\n",
    "            result = queryProcessor.process_query(image_path=img_path, reference_texts=combined_texts)\n",
    "            if 'choices' in result:\n",
    "                break  # 如果请求成功，则退出循环\n",
    "        except Exception as e:\n",
    "            print(f\"请求失败，错误信息: {e}\")\n",
    "            time.sleep(2)  # 等待2秒后重试\n",
    "    \n",
    "    # 生成每个样本的结果字典\n",
    "    sample_result = {\n",
    "        \"image_path\": img_path,\n",
    "        \"similar_image_path\": similar_img_path,\n",
    "        \"original_description\": description,\n",
    "        \"extracted_keywords\": keywords,\n",
    "        \"result_text\": [],\n",
    "        \"combined_texts\": combined_texts\n",
    "    }\n",
    "\n",
    "    # 将查询结果的文本内容加入字典\n",
    "    if 'choices' in result:\n",
    "        for choice in result['choices']:\n",
    "            message_content = choice['message']['content']\n",
    "            sample_result[\"result_text\"].append(message_content)\n",
    "    else:\n",
    "        print(f\"无法处理样本: {img_path}，API请求失败\")\n",
    "        sample_result[\"result_text\"].append(\"API请求失败，未返回有效结果。\")\n",
    "\n",
    "    return sample_result\n",
    "\n",
    "# 处理每个随机选择的样本\n",
    "for sample in random_samples:\n",
    "    result = process_sample(sample)\n",
    "    results.append(result)\n",
    "\n",
    "# 将合并后的结果保存到JSON文件\n",
    "json_output_path = \"./results_tmp/result_Retclip.json\"\n",
    "with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON文件已成功生成: {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON文件已成功更新，路径: ./results_tmp/updated_result_Retclip.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 读取现有的JSON文件\n",
    "json_input_path = \"./results_tmp/result_Retclip.json\"\n",
    "with open(json_input_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    try:\n",
    "        data = json.load(json_file)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"现有的JSON文件可能损坏或格式不正确，无法读取。\")\n",
    "        exit()\n",
    "\n",
    "def update_similar_image_path(sample):\n",
    "    img_path = sample['image_path']\n",
    "\n",
    "    # 检索相似的图像和文本，取出第0张图片\n",
    "    try:\n",
    "        scores, retrieved_examples = mmRetriever.retrieve(img_path, k=3)\n",
    "        similar_img_path = retrieved_examples[\"image_path\"][0]  # 使用第0张图片作为相似图片\n",
    "    except Exception as e:\n",
    "        print(f\"在处理 {img_path} 时发生错误: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 更新样本中的 similar_image_path\n",
    "    sample['similar_image_path'] = similar_img_path\n",
    "    return sample\n",
    "\n",
    "# 遍历所有样本，更新 similar_image_path\n",
    "updated_data = []\n",
    "for sample in data:\n",
    "    updated_sample = update_similar_image_path(sample)\n",
    "    if updated_sample:\n",
    "        updated_data.append(updated_sample)\n",
    "\n",
    "# 将更新后的结果保存到新的JSON文件\n",
    "json_output_path = \"./results_tmp/updated_result_Retclip.json\"\n",
    "with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(updated_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON文件已成功更新，路径: {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil  # 用于复制相似图片\n",
    "\n",
    "# 定义数据集路径\n",
    "dataset_dir = \"./datasets\"  # 表示 datasets 目录在当前工作目录下\n",
    "similar_dir = \"./similarset\"  # 用于存储相似图片的目录\n",
    "\n",
    "# 确保 similarset 目录存在\n",
    "if not os.path.exists(similar_dir):\n",
    "    os.makedirs(similar_dir)\n",
    "\n",
    "# 创建 HTML 文件\n",
    "output_html = \"images_cmp_RET_clip_anlaysis.html\"\n",
    "with open(output_html, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"<html><body>\\n\")\n",
    "    f.write(\"<h1>Retinal Images Report</h1>\\n\")\n",
    "\n",
    "    # 图像路径过滤，获取所有图像文件的路径\n",
    "    img_paths_filter = []\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(dataset_dir, filename)\n",
    "            img_paths_filter.append(img_path)\n",
    "\n",
    "    # 过滤出与 img_paths_filter 匹配的数据集样本\n",
    "    filtered_dataset = mmdataset.filter(lambda x: os.path.basename(x['image_path']) in [os.path.basename(p) for p in img_paths_filter])\n",
    "\n",
    "    # 遍历过滤后的数据集\n",
    "    for sample in filtered_dataset:\n",
    "        img_path = sample['image_path']  # 原始图像路径（相对路径或绝对路径）\n",
    "\n",
    "        # 检索相似图像和描述\n",
    "        try:\n",
    "            scores, retrieved_examples = mmRetriever.retrieve(img_path, k=3)\n",
    "            similar_img_path = retrieved_examples[\"image_path\"][0]\n",
    "            similar_description = retrieved_examples[\"description\"][0]\n",
    "\n",
    "            # 将相似图片复制到 similarset 目录\n",
    "            similar_filename = os.path.basename(similar_img_path)  # 获取相似图片的文件名\n",
    "            new_similar_path = os.path.join(similar_dir, similar_filename)\n",
    "            if not os.path.exists(new_similar_path):\n",
    "                shutil.copy(similar_img_path, new_similar_path)  # 复制相似图片到 similarset 目录\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving similar images for {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        original_description = sample[\"description\"]  # 从样本中获取原始描述\n",
    "\n",
    "        # 将原始图像和相似图像及其描述写入 HTML\n",
    "        f.write(f\"<div style='margin-bottom: 40px;'>\\n\")\n",
    "\n",
    "        # 写入图片名（文件名）并排\n",
    "        f.write(\"<table style='width:100%;'>\\n\")\n",
    "        f.write(\"<tr>\\n\")\n",
    "        f.write(f\"<td><strong>Original Image Name:</strong> {os.path.basename(img_path)}</td>\\n\")\n",
    "        f.write(f\"<td><strong>Similar Image Name:</strong> {similar_filename}</td>\\n\")\n",
    "        f.write(\"</tr>\\n\")\n",
    "\n",
    "        # 写入图片并排展示\n",
    "        f.write(\"<tr>\\n\")\n",
    "        f.write(f\"<td><img src='{os.path.join(dataset_dir, os.path.basename(img_path))}' style='width:300px;'></td>\\n\")\n",
    "        f.write(f\"<td><img src='{os.path.join(similar_dir, similar_filename)}' style='width:300px;'></td>\\n\")\n",
    "        f.write(\"</tr>\\n\")\n",
    "\n",
    "        # 写入描述并排展示\n",
    "        f.write(\"<tr>\\n\")\n",
    "        f.write(f\"<td><strong>Description:</strong> {original_description}</td>\\n\")\n",
    "        f.write(f\"<td><strong>Similar Description:</strong> {similar_description}</td>\\n\")\n",
    "        f.write(\"</tr>\\n\")\n",
    "        f.write(\"</table>\\n\")\n",
    "        f.write(\"<hr>\")  # 添加分隔线\n",
    "        f.write(\"</div>\\n\")\n",
    "    \n",
    "    f.write(\"</body></html>\\n\")\n",
    "\n",
    "print(f\"HTML report saved as {output_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmretinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
