{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model imports\n",
    "import faiss\n",
    "import json\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import clip\n",
    "import git_image\n",
    "import requests\n",
    "# helper imports\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import List, Union, Tuple\n",
    "# visualisation imports\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import KeepFIT.keepfit.modeling.model as keepfit \n",
    "from torchvision import models\n",
    "from classifiers.train import my_transform\n",
    "\n",
    "from datasets import load_from_disk, Dataset, Features, Sequence, Value\n",
    "from transformers import AutoTokenizer, RagRetriever, DPRQuestionEncoder, DPRContextEncoder, RagTokenizer, RagSequenceForGeneration\n",
    "from tqdm import tqdm\n",
    "from faiss import IndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        query = [item['query'] for item in data]\n",
    "        img_path = [item['image_path'] for item in data]\n",
    "    return query,img_path\n",
    "\n",
    "def get_image_paths(directory, number=None) :\n",
    "    image_paths = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpeg'):\n",
    "            image_paths.append(os.path.join(directory, filename))\n",
    "            if number is not None and count == number:\n",
    "                return [image_paths[-1]]\n",
    "            count += 1\n",
    "    return image_paths\n",
    "\n",
    "def get_features_from_image_path(model,image_paths):\n",
    "    images=[]\n",
    "    for image_path in image_paths:\n",
    "        image=Image.open(image_path).convert(\"RGB\")\n",
    "        image=torch.tensor(model.preprocess_image(np.array(image)))\n",
    "        images.append(image)\n",
    "    images=torch.stack(images)\n",
    "    with torch.no_grad():\n",
    "        image_features=model.vision_model(images)\n",
    "    return image_features\n",
    "\n",
    "def find_entry(data, key, value):\n",
    "    for entry in data:\n",
    "        if entry.get(key) == value:\n",
    "            return entry\n",
    "    return None\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read())\n",
    "        return encoded_image.decode('utf-8')\n",
    "\n",
    "def image_query(query, image_path, similar_path=None, description=None,headers=None,labels=None,infor=None):\n",
    "    messages = []\n",
    "    if similar_path!=None:\n",
    "        similar_url=git_image.get_file_url(similar_path)\n",
    "        reference_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\":[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Answer Users question with the background information. The frist iamge is the reference image which is similar to query image.\"\n",
    "                }\n",
    "        ]\n",
    "        }\n",
    "        background_message={\n",
    "        \"role\": \"user\",\n",
    "        \"content\":[\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": similar_url\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"The background information you may use:\\nThe description of the image below is: {description}\"\n",
    "                }\n",
    "        ]\n",
    "        }\n",
    "        messages.append(reference_message)\n",
    "        messages.append(background_message)\n",
    "    # 构造带有目标图片和问题的消息\n",
    "    image_url=git_image.add_file_to_repo(os.path.basename(image_path))\n",
    "    for i,label in enumerate(labels):\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\":[\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"the image's labels are {label}.\\n \\\n",
    "                                Some information about the labels is: {infor[i]}.\\n \\\n",
    "                                Please answer the following question about the image:{query}\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": image_url\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "            ]\n",
    "        })\n",
    "    messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\":[\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"Please answer the following question about the image:{query}\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": image_url\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "            ]\n",
    "        })\n",
    "    print(messages)\n",
    "    payloads={\n",
    "        \"model\": 'gpt-4o',\n",
    "        \"messages\":messages,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    # 发送请求\n",
    "    # response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payloads)\n",
    "    # json_data = response.json()\n",
    "    # print(json_data)\n",
    "    # git_image.delete_file_from_repo(os.path.basename(image_path))\n",
    "    # if 'choices' in json_data and json_data['choices']:\n",
    "    #     content = json_data['choices'][0]['message']['content']\n",
    "    #     return content\n",
    "\n",
    "def getlabel(out,disease):\n",
    "    out = F.softmax(out, dtype=torch.float32,dim=1)\n",
    "    out = out.argmax(dim=1)\n",
    "    if disease=='Glaucoma':\n",
    "        if out == 1:\n",
    "            return 'Glaucoma'\n",
    "        elif out == 2:\n",
    "            return 'Unknown Glaucoma'\n",
    "    if disease=='Diabetic':\n",
    "        if out != 0 :\n",
    "            return  f'Diabetic level {out}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights: IMAGENET1K_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jqxu/anaconda3/envs/mmretinal/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model weight from: /home/jqxu/Ragas/weights/KeepFIT (50%flair+MM).pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key=\"sk-t502-PgPqzhUSpTAYsjVSTA94T3BlbkFJHXpMvF0k0Ge7bQiZqDmI\"\n",
    "device = \"cuda\"\n",
    "text_dataset_path = \"/home/jqxu/Ragas/TextRetrive/TextDataset\"\n",
    "text_index_path = \"/home/jqxu/Ragas/TextRetrive/index.faiss\"\n",
    "json_path=\"/home/jqxu/Ragas/query.json\"\n",
    "model = keepfit.KeepFITModel(vision_type='resnet_v2', out_path='./output', from_checkpoint=True, vision_pretrained=True,\n",
    "                    weights_path=f'/home/jqxu/Ragas/weights/KeepFIT (50%flair+MM).pth')\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "text_dataset = load_from_disk(text_dataset_path)\n",
    "\n",
    "# 初始化RAG Retriever和tokenizer\n",
    "rag_retriever = RagRetriever.from_pretrained(\n",
    "    \"facebook/rag-token-base\",\n",
    "    index_name=\"custom\",\n",
    "    passages_path=text_dataset_path,\n",
    "    index_path=text_index_path,\n",
    "    device=device,\n",
    ")\n",
    "rag_tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
    "\n",
    "# 初始化DPR Question Encoder和tokenizer\n",
    "dpr_question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(device)\n",
    "dpr_tokenizer = AutoTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "#glaucama classifier\n",
    "glaucama_cls= models.resnet50()\n",
    "num_features = glaucama_cls.fc.in_features\n",
    "glaucama_cls.fc = nn.Linear(num_features, 3)  \n",
    "glaucama_cls.load_state_dict(torch.load('/home/jqxu/Ragas/classifiers/Glaucoma/resnet50_epoch70.pth'))\n",
    "glaucama_cls.to(device).eval()\n",
    "transform=my_transform((224,224))\n",
    "\n",
    "#diabetic classifier\n",
    "diabetic_cls = models.resnet50()\n",
    "num_features = diabetic_cls.fc.in_features\n",
    "diabetic_cls.fc = nn.Linear(num_features, 5)\n",
    "diabetic_cls.load_state_dict(torch.load('/home/jqxu/Ragas/classifiers/Diabetic/resnet50_epoch10.pth'))\n",
    "diabetic_cls.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3894594/826010011.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image=torch.tensor(model.preprocess_image(np.array(image)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jqxu/Ragas/datasets/train1.jpeg\n",
      "What is the color of the sky?\n",
      "labels : ['Glaucoma']\n",
      "BRANCH RETINAL VEIN OBSTRUCTION(OCCLUSION) - DIAGNOSTIC EVALUATIONSystemic workup: Includes an evaluation for systemic arterial hypertension and increased body mass. A history of glaucoma has also been associated with branch retinal vein occlusion.\n",
      "HYPOTONY MACULOPATHY - EPIDEMIOLOGY AND ETIOLOGYPatients with chronically low intraocular pressure from a wound leak, cyclodialysis cleft, or excessive filtering after glaucoma surgery may develop secondary retinal changes.\n",
      "/home/jqxu/Ragas/datasets/train4.jpeg\n",
      "[{'role': 'system', 'content': [{'type': 'text', 'text': 'Answer Users question with the background information. The frist iamge is the reference image which is similar to query image.'}]}, {'role': 'user', 'content': [{'type': 'image_url', 'image_url': {'url': 'https://github.com/CazeroZ/Images/raw/master/train4.jpeg'}}, {'type': 'text', 'text': 'The background information you may use:\\nThe description of the image below is: 古月方源，小说蛊真人的主角'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': \"the image's labels are Glaucoma.\\n                                 Some information about the labels is: BRANCH RETINAL VEIN OBSTRUCTION(OCCLUSION) - DIAGNOSTIC EVALUATIONSystemic workup: Includes an evaluation for systemic arterial hypertension and increased body mass. A history of glaucoma has also been associated with branch retinal vein occlusion..\\n                                 Please answer the following question about the image:\\n        What is the color of the sky?\\n        \"}, {'type': 'image_url', 'image_url': {'url': 'https://github.com/CazeroZ/Images/raw/master/train1.jpeg'}}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Please answer the following question about the image:\\n        What is the color of the sky?\\n        '}, {'type': 'image_url', 'image_url': {'url': 'https://github.com/CazeroZ/Images/raw/master/train1.jpeg'}}]}]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#encode dataset\n",
    "direc = '/home/jqxu/Ragas/datasets'\n",
    "json_path = '/home/jqxu/Ragas/query.json'\n",
    "image_paths = get_image_paths(direc)\n",
    "image_features = get_features_from_image_path(model,image_paths)\n",
    "index = faiss.IndexFlatIP(image_features.shape[1])\n",
    "index.add(np.array(image_features.cpu()))\n",
    "data = []\n",
    "query_text,query_image_path=read_json(json_path)\n",
    "for image_path,user_query in zip(query_image_path,query_text):\n",
    "    #encodee query image and get labels\n",
    "    print(image_path)\n",
    "    print(user_query)\n",
    "    #image_path = '/home/jqxu/Ragas/datasets/figure01-01A.jpg'\n",
    "    img=transform(Image.open(image_path).convert('RGB'))\n",
    "    img=img.unsqueeze(0).to(device)\n",
    "    labels=[]\n",
    "    glaucama=getlabel(glaucama_cls(img), 'Glaucoma')\n",
    "    if glaucama:\n",
    "        labels.append(glaucama)\n",
    "    diabetic=getlabel(diabetic_cls(img), 'Diabetic')\n",
    "    if diabetic:\n",
    "        labels.append(diabetic)\n",
    "    print(f'labels : {labels}')\n",
    "    if len(labels) ==0:\n",
    "        labels.append('Healthy')\n",
    "    image_search_embedding = get_features_from_image_path(model,[image_path])\n",
    "\n",
    "    #load VQA dataset\n",
    "    with open('/home/jqxu/Ragas/description.json', 'r') as file:\n",
    "        file = json.load(file)\n",
    "        for item in file:\n",
    "            data.append(item)\n",
    "\n",
    "    #text RAG:\n",
    "    with torch.no_grad():\n",
    "        doc_dicts=[]\n",
    "        for label in labels:\n",
    "            input = dpr_tokenizer(label, return_tensors=\"pt\").to(\"cuda\")\n",
    "            question_hidden_states = dpr_question_encoder(**input).pooler_output\n",
    "            question_hidden_states = question_hidden_states.detach().cpu().numpy()\n",
    "            retrieved_doc_embeds, doc_ids, doc_dict = rag_retriever.retrieve(question_hidden_states, n_docs=7)\n",
    "            doc_dicts.append(doc_dict)\n",
    "\n",
    "    text_retrive=[]\n",
    "    for doc_dict in doc_dicts:\n",
    "        if doc_dict:\n",
    "            doc_dict = doc_dict[0]  \n",
    "            if isinstance(doc_dict, dict): \n",
    "                titles = doc_dict.get('title', [])[:2]\n",
    "                texts = doc_dict.get('text', [])[:2]\n",
    "                for title, text in zip(titles, texts):\n",
    "                    print(title + text)\n",
    "                    text_retrive.append(title + text)\n",
    "        else:\n",
    "            print(f\"Unexpected type for doc_dict: {type(doc_dict)}\")\n",
    "    \n",
    "\n",
    "    #find similar image\n",
    "    distances, indices = index.search(np.array(image_search_embedding.reshape(1, -1).cpu()), 2) #2 signifies the number of topmost similar images to bring back\n",
    "    distances = distances[0]\n",
    "    indices = indices[0]\n",
    "    indices_distances = list(zip(indices, distances))\n",
    "    indices_distances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    similar_path = get_image_paths(direc, indices_distances[1][1])[0]\n",
    "    print(similar_path)\n",
    "    element = find_entry(data, 'image_path', similar_path)\n",
    "\n",
    "    #generate query\n",
    "    query = f\"\"\"\n",
    "        {user_query}\n",
    "        \"\"\"\n",
    "\n",
    "    print(image_query(query,image_path,similar_path,element[\"description\"],headers=headers,labels=labels,infor=text_retrive))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava-med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
